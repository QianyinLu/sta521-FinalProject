---
title: "Part-II Complex Model"
author: "Yi Mi"
geometry: margin=1in
date: "11/30/2019"
output: 
    pdf_document:
        highlight: pygment
        toc: false
        toc_depth: 2
        fig_caption: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, 
                      warning=FALSE, 
                      message=FALSE,
                      fig.align="center",
                      fig.pos='H', 
                      results="asis")
```


```{r pakages}
library(tidyverse)
library(knitr)
library(gbm)
library(xtable)
library(kableExtra)
library(broom)
library(car)
library(GGally)
```


## Introduction


## EDA

Based on EDA of Part-I, we completed our data cleaning on our data as follows: 
 
 - We 

```{r read-data}
load("paintings_train.Rdata")
load("paintings_test.Rdata")
```



```{r data cleaning}
# merge the two dataset first
paint <-rbind(paintings_train, paintings_test)
# Fix position > 1
paint$position[paint$position > 1] <- paint$position[paint$position > 1]/100
# regroup some categorical variables
paint <- paint %>%
  mutate(winningbiddertype = as.factor(dplyr::recode(na_if(winningbiddertype,""),
                                              .missing = 'U')),
         endbuyer = as.factor(dplyr::recode(na_if(endbuyer,""),
                                     .missing = 'L',
                                     'E' = 'L',
                                     'B' = 'H',
                                     'c' = 'H',
                                     'd' = 'H')),
         dealer = as.factor(dplyr::recode(dealer,
                                     'L' = 'L',
                                     'P' = 'L',
                                     'R' = 'H',
                                     'J' = 'L')),
         Interm = as.factor(dplyr::recode(Interm,
                                   .missing = 0,
                                   `0` = 0,
                                   `1` = 1)),
         authorstyle = dplyr::recode(authorstyle,
                                      "n/a" = 0,
                                      .default = 1),
         type_intermed = as.factor(dplyr::recode(na_if(type_intermed,''),
                                          .missing='Unknown')),
         Shape = as.factor(dplyr::recode(na_if(Shape,""),
                                  .missing = 'other',
                                  'squ_rect' = 'squ_rect',
                                  .default = 'other')),
         materialCat = as.factor(dplyr::recode(na_if(materialCat,""),
                                        .missing = 'other')),
         school_pntg = as.factor(dplyr::recode(school_pntg,
                                               'S' = 'X',
                                               'A' = 'X',
                                               'G' = 'X')), 
         origin_cat = as.factor(dplyr::recode(origin_cat,
                                    "S" = "O")), 
         nfigures = as.factor(dplyr::recode(nfigures,
                                            `0` = 0,
                                            .default = 1)),
         price = as.numeric(str_remove_all(paint$price, ","))) %>% 
  # change variables into appropriate format
  mutate_at(vars(dealer, origin_author, origin_cat, school_pntg, 
                 diff_origin, artistliving, authorstyle, 
                 winningbiddertype, endbuyer, Interm, type_intermed, 
                 material, mat, materialCat, Shape, engraved, original, 
                 prevcoll, othartist, paired, figures, finished, lrgfont, 
                 relig, landsALL, lands_sc, lands_elem, lands_figs, lands_ment, 
                 arch, mytho, peasant, othgenre, singlefig, portrait, 
                 still_life, discauth, history, allegory, pastorale,other), as.factor) 
# impute Surface on different groups
paint <- paint %>% mutate(Key = seq(1:nrow(paint)))
paint1 <- paint %>% filter(materialCat == 'canvas', relig == 1) %>% 
  mutate(Surface = dplyr::recode(Surface,
                          `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm = T)))
paint2 <- paint %>% filter(materialCat == 'canvas', relig == 0) %>%
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm=T)))
paint3 <- paint %>% filter(materialCat == 'copper', relig == 1) %>% 
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm = T)))
paint4 <- paint %>% filter(materialCat == 'copper', relig == 0) %>%
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm=T)))
paint5 <- paint %>% filter(materialCat == 'other', relig == 1) %>% 
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm = T)))
paint6 <- paint %>% filter(materialCat == 'other', relig == 0) %>%
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm=T)))
paint7 <- paint %>% filter(materialCat == 'wood', relig == 1) %>% 
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm = T)))
paint8 <- paint %>% filter(materialCat == 'wood', relig == 0) %>%
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm=T)))
paint <- rbind(paint1, paint2, paint3, paint4, paint5, paint6, paint7, paint8) %>% 
  arrange(Key) %>% 
  select(-Key) %>% 
  dplyr::select(-c("sale", "lot", "count","subject", "author", "origin_author", 
                   "winningbidder","type_intermed","material","mat", "still_life", "portrait",
                   "Diam_in","Surface_Rnd","Surface_Rect","Width_in","Height_in","other",
                   "pastorale","history","lands_ment","original","allegory","position",
                   "school_pntg", "winningbiddertype", "figures", "singlefig"))
paint$Surface <- log(paint$Surface)
# paint$year_sq <- (paint$year)^2
# paint$year_cu <- (paint$year)^3
# summary(paint)
remove <- c("attributed to ", "after ", "in the manner of ", "in the taste of ", "in the genre of ", "in the style of ")
paint$authorstandard <- str_remove_all(paint$authorstandard, 
                                             paste(remove, collapse = "|"))
# Split back into train and test
paint_train <- paint %>% filter(!is.na(logprice))
paint_test <- paint %>% filter(is.na(logprice))
level <- c(1, 0)
train_author <- paint_train %>% 
  group_by(authorstandard) %>% 
  summarise(avg_price = mean(price)) %>% 
  arrange(desc(avg_price)) %>% 
  mutate(expensive = case_when(avg_price >= 1500 ~ level[1],
                           avg_price < 1500 ~ level[2]))
ggplot(data = train_author, aes(y = avg_price, x = 1:473, col = as.factor(expensive))) +
  geom_point() +
  labs(title = "Average price for each author", x = "Rank", y = "Average price")
# attribute each author name to its group
author_group = map(level, ~train_author$authorstandard[train_author$expensive == .x]) %>%
  set_names(level)
# group the training set
paint_train <- paint_train %>% 
  mutate(expensive = case_when(authorstandard %in% author_group[[1]] ~ level[1], 
                           authorstandard %in% author_group[[2]] ~ level[2]) %>% 
           as.factor())
# group the test set using same metric, set new authors to 0
paint_test <- paint_test %>% 
  mutate(expensive = case_when(authorstandard %in% author_group[[1]] ~ level[1], 
                           authorstandard %in% author_group[[2]] ~ level[2]) %>% 
           as.factor)
paint_test$expensive[is.na(paint_test$expensive)] <- level[2]
```

### RF
```{r}
library(randomForest)
rf <- randomForest(logprice ~ year + dealer + origin_cat + diff_origin +  
                    authorstyle + endbuyer + Interm + Surface + materialCat + 
                nfigures + engraved + prevcoll + paired + finished + lrgfont + 
                lands_sc + lands_elem + othgenre + discauth, 
                   data = paint_train, mytry = 6, importance = T)
varImpPlot(rf)
```

### BMA
```{r}
lm_bas <- bas.lm(ini_bic, data = paint_train, 
              prior = "g-prior", alpha = nrow(paint_train), 
              modelprior = uniform(), method = "MCMC")
plot(lm_bas, which = 4)
```

RF
 - should be included: year Surface endbuyer origin_cat dealer lrgfont
 - should be excluded: nfigures engraved discauth lands_sc othgenre 
 - undecided: prevcoll authorstyle finished paired material_cat diff_origin interm 

BMA
 - should be included: year dealer origin_cat diff_origin authorstyle endbuyer interm Surface engraved prevcoll finished lrgfont 
 - should be excluded: discauth,all interactions
 - undecided: nfigures paired(both undecided in RF and BMA) lands_sc othgenre  

Synthesized both method:
 - should be included: year dealer origin_cat endbuyer lrgfont(performed worse) Surface 
 - undecided: authorstyle interm prevcoll finished diff_origin paired

#based on BMA and RF
```{r}
model_yi.1 = lm(logprice~year+dealer+origin_cat+endbuyer+
                  Surface+authorstyle+prevcoll+finished+Interm+
                  diff_origin+paired,
                data = paint_train)
predictions = as.data.frame(
  exp(predict(model_yi.1, newdata=paint_test, 
              interval = "pred")))
save(predictions, file="predict-test.Rdata")
```
Coverage 0.702
RMSE 2172

#my model 
```{r}
model_yi.2 = lm(logprice~year+dealer+origin_cat+
                  endbuyer+Surface+paired+diff_origin+
                  authorstyle+materialCat+finished,
                data = paint_train)
predictions = as.data.frame(
  exp(predict(model_yi.2, newdata=paint_test, 
              interval = "pred")))
save(predictions, file="predict-test.Rdata")
```
Coverage 0.72
RMSE 20XX


Looking at the coefficient summary table, we can get the following conclusion. 

First of all, in our model we got the most important variables *year*, *dealer*, *expensive*, *authorstyle*, *endbuyer* ,*Interm*, *Surface*, *finished*, *lrgfont*, *diff_origin*. 

Then, holding all other variables constant,

  - On average, one unit increase in *year* will lead to 12.0% increase in price. We are 95% confident the increase is between about 10.5% and 13.6%.  
 
  - In data manipulation part, we regrouped *dealer* by grouping 'L' and 'P' together as 'LP' since their corresponding average logprices are similar. Compared to dealer J, dealer LP is expected to lead to 156.8% increase in price, and we are 95% confident the decrease is between about 106.0% and 220.0%; Dealer R is expected to lead to 435.6% increase in price, and we are 95% confident the increase is between about 337.4% and 555.8%.
  
  - If the painting is drawn by an artist whose paintings' average price is higher than $2000, the price is expected to increase by 260.5%. We are 95% confident the increase is between about 192.6% and 344.2%.
  
  - If the authors name is introduced, the price is expected to decrease by 61.2%. We are 95% confident the decrease is between about 48.2% and 70.9%.
  
  - In data manipulation part, we regrouped *endbuyer* by grouping 'U' (identity unknown), 'E'  (expert organizing the sale) and blank data (no information) together as 'EU', grouping 'B' (buyer) and 'C' (collector) together as 'C' and left 'D' (dealer) as it was. Compared to an endbuyer in group 'C', a group 'D' endbuyer is expected to lead to 21.2% decrease in price, and we are 95% confident the decrease is between about 4.1% and 35.4%; A group 'EU' endbuyer is expected to lead to 50.6% decrease in price, and we are 95% confident the decrease is between about 39.6% and 59.6%.  

  - If an intermediary is involved in the transaction, the price is expected to increase by 99.6%. We are 95% confident the increase is between about 53.7% and 159.1%.

  - We expect 10% increase in *Surface* will increase the price by 3.0% ($1.1^{\hat{\beta}_1} - 1$). We are 95% confident the increase is between about 2.5% and 3.5%.

  - If the the painting is finished, the price is expected to increase by 135.1%. We are 95% confident the increase is between about 96.9% and 180.6%.
  
  - If the dealer devotes an additional paragraph, the price is expected to increase by 143.6%. We are 95% confident the increase is between about 92.6% and 208.0%.
  
  - If origin_author is different than origin_cat, the price is expected to decrease by 38.7%. We are 95% confident the increase is between about 27.6% and 48.1%.

Looking at the p-values, we find that all variables are extremelly important.

In EDA process of part-I, we imputed the NA's in *Surface* to median value of *Surface*, we discarded the variable *authorstandard* and we grouped *dealer* and *endbuyer* into 4 and 5 levels respectively. And then we fitted a linear model. However, in part-II, our model were not good as we expected. We returned to EDA process and realized that there was still some infomation in raw data we did not pay enough attention. And thus we reworked the data manipulation process. In part-II, we devided the surface data into 8 groups based on the correlated data and imputed median value for each group respectively. We created a binary variable *expensive* representing if the painting is drawn by a painter whose paintings' averaging price is higher than $2000. And we also regrouped dealer and endbuyer to less levels to avoid overfitting. After data re-manipulation, the model performed better. 

Before the test data was updated, we always felt upset because the coverage was always lower than our expectaiton even if we thought our model was already good enough. Some of our team members were so disappointed that they even thought about discarding *year* since this operation improved the coverage a lot. But luckily we were pretty sure that all operations need to be reasonable. We could not randomly discard some variables just for better coverage and RMSE. So we still followed the rigorous modeling process to fit our model, even if we did not get a score in wercker.

After a few attempts, we had to give up our most prefered model Random Forests since it could not yield prediction interval and the quantile method was not ideal. We then used Bayesian Model Averaging to do feature selection and cross referenced the results of RF and BMA and fitted a new linear model, which achieved relatively great performance. We found that succinct model usually have higher coverage and easy interpretability so it's easier for clients to understand and linear model is generally a great model choice. 

In terms of painting price prediction, we think that due to the particularity of art, the author often has a great impact on the price. Besides, year of sale, dealer, if the authors name is introduced, type of end buyer, whether or not an intermediary is involved in the transaction, surface of painting, if the painting is finished, if the dealer devotes an additional paragraph, if origin of author is different than origin of painting also have a great impact on the price of paintings.

Just test
