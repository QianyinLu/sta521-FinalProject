---
title: "Part-II Complex Model"
author: "Chenxi Wu"
geometry: margin=1in
date: "11/30/2019"
output: 
    pdf_document:
        highlight: pygment
        toc: false
        toc_depth: 2
        fig_caption: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, 
                      warning=FALSE, 
                      message=FALSE,
                      fig.align="center",
                      fig.pos='H', 
                      results="asis")
```

```{r pakages}
library(tidyverse)
library(knitr)
library(gbm)
library(xtable)
library(kableExtra)
library(broom)
library(car)
library(GGally)
library(caret)
library(randomForest)
```

## Introduction


## EDA

Based on EDA of Part-I, we completed our data cleaning on our data as follows: 
 
 - *position* has values greater than 1 which should be data entry errors, we divided them by 100 to get the right value. 
 - The original dataset contains lots of missing values and NA's, like *winningbiddertype*, *endbuyer*, *authorstyle*, *Interm* and *type_intermed*, we filled the missing values with "U", "Unknown" or 0 according to the description of codebook. 
 - Most of observations for *Shape* are "squ_rect", so we regroup other shapes to "other". After testing the average *logprice* of "other" and the missing ones, we decided to recode the missing values to "other" since they have similar average *logprice*. For same reasoning we recoded the missing values in MaterialCat to "other". 
 - To alleviate the class imbalance problem of *school-pntg*, *origin_cat*, *mat* and *material*, we regrouped levels with fewer observations to larger levels. 
 - We transformed *nfigures* into a binary variable where values other than 0 are set to 1. 
 - In Part-I we imputed the NA's in *Surface* to median value of *Surface*. Here we tried more advanced methods by regressing other variables on *Surface* to see the correlations. We found out that *Surface* was correlated with *MaterialCat* and *relig*, from which we devided the data into 8 groups and imputed median value for each group respectively. We tested the efficiency of the new imputation and the result showed that *Surface* has more explanation power than before. 
 - In Part-I we discarded the variable *authorstandard* which can be a strong predictor. Here we cleaned *authorstandard* so it contains fewer unique values. We computed the average price for each author and ploted them in a descending order (See plot below). The plot showed that the relationship between author and price is significant. So we created a binary variable *expensive*, we set the authors with high average price to 1 and the others to 0. 
 - To avoid overfitting, we regrouped *dealer* and *endbuyer* into three levels respectively. Specifically, we combined 'L' and 'P' in *dealer* and 'E' and 'U' in *endbuyer*. 

```{r read-data}
load("paintings_train.Rdata")
load("paintings_test.Rdata")
```



```{r data cleaning}
# merge the two dataset first
paint <-rbind(paintings_train, paintings_test)

# Fix position > 1
paint$position[paint$position > 1] <- paint$position[paint$position > 1]/100

# regroup some categorical variables
paint <- paint %>%
  mutate(winningbiddertype = as.factor(dplyr::recode(na_if(winningbiddertype,""),
                                              .missing = 'U')),
         dealer = as.factor(dplyr::recode(dealer, 
                                          'L' = 'LP', 
                                          'P' = 'LP')), 
         endbuyer = as.factor(dplyr::recode(na_if(endbuyer,""),
                                     .missing = 'EU',
                                     'E' = 'EU', 
                                     'U' = 'EU',
                                     'B' = 'C')),
         Interm = as.factor(dplyr::recode(Interm,
                                   .missing = 0,
                                   `0` = 0,
                                   `1` = 1)),
         authorstyle = dplyr::recode(authorstyle,
                                      "n/a" = 0,
                                      .default = 1),
         type_intermed = as.factor(dplyr::recode(na_if(type_intermed,''),
                                          .missing='Unknown')),
         Shape = as.factor(dplyr::recode(na_if(Shape,""),
                                  .missing = 'other',
                                  'squ_rect' = 'squ_rect',
                                  .default = 'other')),
         materialCat = as.factor(dplyr::recode(na_if(materialCat,""),
                                        .missing = 'other')),
         school_pntg = as.factor(dplyr::recode(school_pntg,
                                               'S' = 'X',
                                               'A' = 'X',
                                               'G' = 'X')), 
         origin_cat = as.factor(dplyr::recode(origin_cat,
                                    "S" = "O")), 
         nfigures = as.factor(dplyr::recode(nfigures,
                                            `0` = 0,
                                            .default = 1)),
         price = as.numeric(str_remove_all(paint$price, ","))) %>% 
  # change variables into appropriate format
  mutate_at(vars(dealer, origin_author, origin_cat, school_pntg, 
                 diff_origin, artistliving, authorstyle, 
                 winningbiddertype, endbuyer, Interm, type_intermed, 
                 material, mat, materialCat, Shape, engraved, original, 
                 prevcoll, othartist, paired, figures, finished, lrgfont, 
                 relig, landsALL, lands_sc, lands_elem, lands_figs, lands_ment, 
                 arch, mytho, peasant, othgenre, singlefig, portrait, 
                 still_life, discauth, history, allegory, pastorale,other), as.factor) 


# impute Surface on different groups
paint <- paint %>% mutate(Key = seq(1:nrow(paint)))
paint1 <- paint %>% filter(materialCat == 'canvas', relig == 1) %>% 
  mutate(Surface = dplyr::recode(Surface,
                          `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm = T)))
paint2 <- paint %>% filter(materialCat == 'canvas', relig == 0) %>%
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm=T)))
paint3 <- paint %>% filter(materialCat == 'copper', relig == 1) %>% 
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm = T)))
paint4 <- paint %>% filter(materialCat == 'copper', relig == 0) %>%
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm=T)))
paint5 <- paint %>% filter(materialCat == 'other', relig == 1) %>% 
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm = T)))
paint6 <- paint %>% filter(materialCat == 'other', relig == 0) %>%
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm=T)))
paint7 <- paint %>% filter(materialCat == 'wood', relig == 1) %>% 
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm = T)))
paint8 <- paint %>% filter(materialCat == 'wood', relig == 0) %>%
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm=T)))

paint <- rbind(paint1, paint2, paint3, paint4, paint5, paint6, paint7, paint8) %>% 
  arrange(Key) %>% 
  select(-Key) %>% 
  dplyr::select(-c("sale", "lot", "count","subject", "author", "origin_author", 
                   "winningbidder","type_intermed","material","mat", "still_life", "portrait",
                   "Diam_in","Surface_Rnd","Surface_Rect","Width_in","Height_in","other",
                   "pastorale","history","lands_ment","original","allegory","position",
                   "school_pntg", "winningbiddertype", "figures", "singlefig"))

paint$Surface <- log(paint$Surface)
# paint$year_sq <- (paint$year)^2
# paint$year_cu <- (paint$year)^3
# summary(paint)

remove <- c("attributed to ", "after ", "in the manner of ", "in the taste of ", "in the genre of ", "in the style of ")
paint$authorstandard <- str_remove_all(paint$authorstandard, 
                                             paste(remove, collapse = "|"))
# Split back into train and test
paint_train <- paint %>% filter(!is.na(logprice))
paint_test <- paint %>% filter(is.na(logprice))

level <- c(1, 0)
train_author <- paint_train %>% 
  group_by(authorstandard) %>% 
  summarise(avg_price = mean(price)) %>% 
  arrange(desc(avg_price)) %>% 
  mutate(expensive = case_when(avg_price >= 1500 ~ level[1],
                           avg_price < 1500 ~ level[2]))

ggplot(data = train_author, aes(y = avg_price, x = 1:473, col = as.factor(expensive))) +
  geom_point() +
  labs(title = "Average price for each author", x = "Rank", y = "Average price")

# attribute each author name to its group
author_group = map(level, ~train_author$authorstandard[train_author$expensive == .x]) %>%
  set_names(level)

# group the training set
paint_train <- paint_train %>% 
  mutate(expensive = case_when(authorstandard %in% author_group[[1]] ~ level[1], 
                           authorstandard %in% author_group[[2]] ~ level[2]) %>% 
           as.factor())

# group the test set using same metric, set new authors to 0
paint_test <- paint_test %>% 
  mutate(expensive = case_when(authorstandard %in% author_group[[1]] ~ level[1], 
                           authorstandard %in% author_group[[2]] ~ level[2]) %>% 
           as.factor)
paint_test$expensive[is.na(paint_test$expensive)] <- level[2]
```

```{r try}
lm1 <- lm(logprice~expensive, data = paint_train)
summary(lm1)

ggplot(paint_train, aes(x = endbuyer, y = logprice))+
  geom_boxplot(show.legend = T)
```



```{r ggpairs}
ggpairs(paint_train, columns = c(5, 1:4, 8),
        lower = list(continuous = wrap("points", alpha = 0.5, size = 0.3)))+
  theme(axis.text = element_text(angle = 45, hjust = 1))
ggpairs(paint_train, columns = c(5, 9:13),
        lower = list(continuous = wrap("points", alpha = 0.5, size = 0.3)))+
  theme(axis.text = element_text(angle = 45, hjust = 1))
ggpairs(paint_train, columns = c(5, 14:19),
        lower = list(continuous = wrap("points", alpha = 0.5, size = 0.3)))+
  theme(axis.text = element_text(angle = 45, hjust = 1))
ggpairs(paint_train, columns = c(5, 20:25),
        lower = list(continuous = wrap("points", alpha = 0.5, size = 0.3)))+
  theme(axis.text = element_text(angle = 45, hjust = 1))
ggpairs(paint_train, columns = c(5, 26:32),
        lower = list(continuous = wrap("points", alpha = 0.5, size = 0.3)))+
  theme(axis.text = element_text(angle = 45, hjust = 1))
```
For EDA in Part-II, we added pairwise plot to have a general view of the interactions of all the variables. 


## Discussion of preliminary model Part I


## Development of the final model

We tried several complex models to better depict the behaviour of the response variable. The findings of those models are summarised as below. 

### Random Forrest

Since we have many variables and the interactions among them can be involved, a tree model seems to be appropriate for the setting. To alleviate the unstability of single tree models, we used random forest method to achieve more robust estimation. We select *year*, *dealer*, *origin_cat*, *diff_origin*, *expensive*, *authorstyle*,*endbuyer*, *Interm*, *Surface*, *materialCat*, *nfigures*, *engraved*, *prevcoll*, *paired*, *finished*, *lrgfont*, *lands_sc*, *lands_elem*, *othgenre*, *discauth* as predictors. Below is the important variable plot and the top 10 most important variable table. The 10 most important variables are *experience*, *year*, *Surface*, *endbuyer*, *dealer*, *materialCat*, *origin_cat*, *paired*, *Irgfont* and *finished*. 
  
To assess the performance of the random forest model, we first evaluated it using training set which achieved a training RMSE of `r rf_rmse`. However when we used it for test set, the prediction contains only a point estimate instead of a prediction interval. We tried to compute the interval using the quantile method, but the coverage is not ideal, which might due to the narrower interval. So we move on to other variable selection method like Bayesian Model Averaging. 

```{r tree}
library(randomForest)
set.seed(11)
rf <- randomForest(logprice ~ year + dealer + origin_cat + diff_origin + expensive + 
                         authorstyle + endbuyer + Interm + Surface + materialCat + 
                         nfigures + engraved + prevcoll + paired + finished + lrgfont + 
                         lands_sc + lands_elem + othgenre + discauth, 
                   data = paint_train, mytry = 6, importance = T)
varImpPlot(rf)


rf <- randomForest(logprice ~ ., 
                   data = paint_train, mytry = 6, importance = T)
varImpPlot(rf)
ImpMeasure<-data.frame(Overall = varImp(rf)$Overall)
ImpMeasure$Vars<-rownames(varImp(rf))
kable(ImpMeasure[order(-ImpMeasure$Overall),][1:10,])

# training set 
rf_pred_train <- predict(rf, newdata = paint_train, type = "response")
rmse = function(y, ypred) {
  rmse = sqrt(mean((y - ypred)^2))
return(rmse)
}

rf_rmse <- rmse(exp(paint_train$logprice), exp(rf_pred_train))
# compare <- cbind(paint_train, ypred = rf_pred_train)
# ggplot(compare, aes(x = logprice, y = ypred)) +
#   geom_point(size = 0.5) + 
#   geom_abline(intercept = 0, slope = 1, col = "light pink") +
#   geom_smooth(method = "lm", se = T)
```

```{r test set validation}
pred1 <- predict(rf, newdata = paint_test, predict.all=TRUE)

pred1_int <- apply(pred1$individual, 1, function(x) {
  # c(mean(x) + c(-2, 2) * sd(x),
  quantile(x, c(0.5, 0.025, 0.975))
})

predictions <- t(exp(pred1_int)) %>% as.data.frame()
colnames(predictions) <- c("fit", "lwr", "upr")
save(predictions, file="predict-test.Rdata")
```


```{r full model}
# paint_train$year <- scale(paint_train$year, scale = F)
model_ini <- lm(logprice ~ year + dealer + origin_cat + diff_origin + expensive +
                         authorstyle + endbuyer + Interm + Surface + materialCat + 
                         nfigures + engraved + prevcoll + paired + finished + lrgfont + 
                         lands_sc + lands_elem + othgenre + discauth + (year + authorstyle + discauth):dealer + year:discauth, data = paint_train)

summary(model_ini)

n <- nrow(paint_train)
ini_bic <- step(model_ini, trace = F, k = log(n))
ini_aic <- step(model_ini, trace = F, k = 2)
summary(ini_bic)
summary(ini_aic)
```

```{r predict-model2, echo=FALSE}
# replace model1 with model2 here
# paint_test$year <- scale(paint_test$year, scale = F)
predictions = as.data.frame(
  exp(predict(ini_bic, newdata=paint_test, 
              interval = "pred")))
save(predictions, file="predict-test.Rdata")
```


```{r bma}
library(BAS)
set.seed(11)
bas <- bas.lm(as.formula(model_ini), data = paint_train, 
              prior = "g-prior", alpha = nrow(paint_train), 
              modelprior = uniform(), method = "MCMC")

plot(bas, which = 4)

x <- predict(bas, estimator = "BMA", newdata = paint_test, se.fit = T)
ints = cbind(x$Ypred + qnorm(0.025) * x$se.pred, x$Ypred - qnorm(0.025) * x$se.pred)
```


