---
title: "Part-II Complex Model"
author: "Chenxi Wu, George Lindner, Qianyin Lu, Yi Mi"
date: "11/30/2019"
output:
  pdf_document:
    fig_caption: yes
    highlight: pygment
    toc: no
    toc_depth: 2
geometry: margin=1in
header-includes:
   \usepackage{setspace} \linespread{1.15}
   \renewcommand{\abstractname}{Summary}
   \usepackage{float}
   \usepackage{amsmath}
   \usepackage{graphicx}
   \usepackage{multirow}
   \usepackage{makecell}
   \usepackage{caption}
   \captionsetup[table]{skip=10pt}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, 
                      warning=FALSE, 
                      message=FALSE,
                      fig.align="center",
                      fig.pos='H', 
                      results="asis")
```

```{r packages, echo = F, message = F, warning = F}
library(tidyverse)
library(knitr)
library(gbm)
library(xtable)
library(kableExtra)
library(broom)
library(car)
library(GGally)
library(caret)
library(randomForest)
library(BAS)
```

## Introduction

Our team of esteemed statisticians was recently hired by a prestigious art historian for a consulting project. We were asked to help build a predictive model in exchange for an A on our STA 521 Final Exam. After much discussion, our team accepted the historian's offer. 
We were given the task of predicting paintings' selling prices at auctions in 18th century Paris. To accomplish this, we used a dataset containing information about each painting's buyer, seller, painter, and characteristics of the painting. 
  
There were two primary objectives in our analysis:
 
 1) To determine which variables (or interactions) drove the price of a painting.  
 2) To determine which paintings were overpriced or and which were underpriced.  
   
The first objective could be accomplished through EDA and modeling. Getting to know the dataset through EDA helps our team identify relationships in the data and develop a sense of which variables might be important for prediction. This developed intuition of the data helps our team begin modeling the logprice variable. After an extensive modeling process, we can report with confidence which variables are drivers of a painting’s selling price.  
When we fit the final model, we can calculate how far each painting’s selling price deviates from our prediction. Positive residuals indicate that a painting sold for more than we think it is worth. The opposite goes for negative residuals. Therefore, we can achieve our second goal through a residual plot analysis of our model.  
We had 1,500 observations to train the model on, along with 750 observations held out as a testing set. There was a total of 59 variables in the dataset, both categorical and continuous.


## EDA and Data Manipulation

Based on EDA of Part-I, we improved our data manipulation on our data as follows: 
 
 - *position* has values greater than 1 which should be data entry errors, we divided them by 100 to get the right value. 
 - The original dataset contains lots of missing values and NA's, like *winningbiddertype*, *endbuyer*, *authorstyle*, *Interm* and *type_intermed*, we filled the missing values with "U", "Unknown" or 0 according to the description of codebook. 
 - Most of observations for *Shape* are "squ_rect", so we regroup other shapes to "other". After testing the average *logprice* of "other" and the missing ones, we decided to recode the missing values to "other" since they have similar average *logprice*. For same reasoning we recoded the missing values in MaterialCat to "other". 
 - To alleviate the class imbalance problem of *school-pntg*, *origin_cat*, *mat* and *material*, we regrouped levels with fewer observations to larger levels. 
 - We transformed *nfigures* into a binary variable where values other than 0 are set to 1 since the empirical distribution of *nfigures* is extremely skwewed and most of the values gather around 0. 
 - In Part-I we imputed the NA's in *Surface* to median value of *Surface*. Here we tried more advanced methods by regressing other variables on *Surface* to see the correlations. We found out that *Surface* was correlated with *MaterialCat* and *relig*, from which we devided the data into 8 groups and imputed median value for each group respectively. We tested the efficiency of the new imputation and the result showed that *Surface* has more explanation power than before. 
 - In Part-I we discarded the variable *authorstandard* which can be a strong predictor. Here we cleaned *authorstandard* so it contains fewer unique values. We computed the average price for each author and ploted them in a descending order (See plot below). The plot showed that the relationship between author and price is significant. So we created a binary variable *expensive*, we set the authors with high average price to 1 and the others to 0. The variable we built actually captures a sginificant amount of variation in the response variable. the regression of *expensive* on *logprice* achieved an $R^2 = 0.157$. 
 - To avoid overfitting, we regrouped *dealer* and *endbuyer* into three levels respectively. Specifically, we combined 'L' and 'P' in *dealer* and 'E' and 'U' in *endbuyer*. 

```{r read-data, echo = F, message = F, warning = F}
load("paintings_train.Rdata")
load("paintings_test.Rdata")
```



```{r data cleaning, echo = F, message = F, warning = F}
# merge the two dataset first
paint <-rbind(paintings_train, paintings_test)

# Fix position > 1
paint$position[paint$position > 1] <- paint$position[paint$position > 1]/100

# regroup some categorical variables
paint <- paint %>%
  mutate(winningbiddertype = as.factor(dplyr::recode(na_if(winningbiddertype,""),
                                              .missing = 'U')),
         dealer = as.factor(dplyr::recode(dealer, 
                                          'L' = 'LP', 
                                          'P' = 'LP')), 
         endbuyer = as.factor(dplyr::recode(na_if(endbuyer,""),
                                     .missing = 'EU',
                                     'E' = 'EU', 
                                     'U' = 'EU',
                                     'B' = 'C')),
         Interm = as.factor(dplyr::recode(Interm,
                                   .missing = 0,
                                   `0` = 0,
                                   `1` = 1)),
         authorstyle = dplyr::recode(authorstyle,
                                      "n/a" = 0,
                                      .default = 1),
         type_intermed = as.factor(dplyr::recode(na_if(type_intermed,''),
                                          .missing='Unknown')),
         Shape = as.factor(dplyr::recode(na_if(Shape,""),
                                  .missing = 'other',
                                  'squ_rect' = 'squ_rect',
                                  .default = 'other')),
         materialCat = as.factor(dplyr::recode(na_if(materialCat,""),
                                        .missing = 'other')),
         school_pntg = as.factor(dplyr::recode(school_pntg,
                                               'S' = 'X',
                                               'A' = 'X',
                                               'G' = 'X')), 
         origin_cat = as.factor(dplyr::recode(origin_cat,
                                    "S" = "O")), 
         nfigures = as.factor(dplyr::recode(nfigures,
                                            `0` = 0,
                                            .default = 1)),
         price = as.numeric(str_remove_all(paint$price, ","))) %>% 
  # change variables into appropriate format
  mutate_at(vars(dealer, origin_author, origin_cat, school_pntg, 
                 diff_origin, artistliving, authorstyle, 
                 winningbiddertype, endbuyer, Interm, type_intermed, 
                 material, mat, materialCat, Shape, engraved, original, 
                 prevcoll, othartist, paired, figures, finished, lrgfont, 
                 relig, landsALL, lands_sc, lands_elem, lands_figs, lands_ment, 
                 arch, mytho, peasant, othgenre, singlefig, portrait, 
                 still_life, discauth, history, allegory, pastorale,other), as.factor) 


# impute Surface on different groups
paint <- paint %>% mutate(Key = seq(1:nrow(paint)))
paint1 <- paint %>% filter(materialCat == 'canvas', relig == 1) %>% 
  mutate(Surface = dplyr::recode(Surface,
                          `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm = T)))
paint2 <- paint %>% filter(materialCat == 'canvas', relig == 0) %>%
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm=T)))
paint3 <- paint %>% filter(materialCat == 'copper', relig == 1) %>% 
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm = T)))
paint4 <- paint %>% filter(materialCat == 'copper', relig == 0) %>%
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm=T)))
paint5 <- paint %>% filter(materialCat == 'other', relig == 1) %>% 
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm = T)))
paint6 <- paint %>% filter(materialCat == 'other', relig == 0) %>%
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm=T)))
paint7 <- paint %>% filter(materialCat == 'wood', relig == 1) %>% 
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm = T)))
paint8 <- paint %>% filter(materialCat == 'wood', relig == 0) %>%
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm=T)))

paint <- rbind(paint1, paint2, paint3, paint4, paint5, paint6, paint7, paint8) %>% 
  arrange(Key) %>% 
  select(-Key) %>% 
  dplyr::select(-c("sale", "lot", "count","subject", "author", "origin_author", 
                   "winningbidder","type_intermed","material","mat", "still_life", "portrait",
                   "Diam_in","Surface_Rnd","Surface_Rect","Width_in","Height_in","other",
                   "pastorale","history","lands_ment","original","allegory","position",
                   "school_pntg", "winningbiddertype", "figures", "singlefig"))

paint$Surface <- log(paint$Surface)
# paint$year_sq <- (paint$year)^2
# paint$year_cu <- (paint$year)^3
# summary(paint)

remove <- c("attributed to ", "after ", "in the manner of ", "in the taste of ", "in the genre of ", "in the style of ")
paint$authorstandard <- str_remove_all(paint$authorstandard, 
                                             paste(remove, collapse = "|"))
# Split back into train and test
paint_train <- paint %>% filter(!is.na(logprice))
paint_test <- paint %>% filter(is.na(logprice))

level <- c(1, 0)
train_author <- paint_train %>% 
  group_by(authorstandard) %>% 
  summarise(avg_price = mean(price)) %>% 
  arrange(desc(avg_price)) %>% 
  mutate(expensive = case_when(avg_price >= 2000 ~ level[1],
                           avg_price < 2000 ~ level[2]))

ggplot(data = train_author, aes(y = avg_price, x = 1:473, col = as.factor(expensive))) +
  geom_point() +
  labs(title = "Average price for each author", x = "Rank", y = "Average price")+
  theme_linedraw()

# attribute each author name to its group
author_group = map(level, ~train_author$authorstandard[train_author$expensive == .x]) %>%
  set_names(level)

# group the training set
paint_train <- paint_train %>% 
  mutate(expensive = case_when(authorstandard %in% author_group[[1]] ~ level[1], 
                           authorstandard %in% author_group[[2]] ~ level[2]) %>% 
           as.factor())

# group the test set using same metric, set new authors to 0
paint_test <- paint_test %>% 
  mutate(expensive = case_when(authorstandard %in% author_group[[1]] ~ level[1], 
                           authorstandard %in% author_group[[2]] ~ level[2]) %>% 
           as.factor)
paint_test$expensive[is.na(paint_test$expensive)] <- level[2]
```


```{r try}
sum <- summary(lm(logprice~expensive, data = paint_train))
r2 <- format(sum$r.squared, digits = 3)
```



```{r ggpairs}
ggpairs(paint_train, columns = c(5, 1:4, 8),
        lower = list(continuous = wrap("points", alpha = 0.5, size = 0.3)))+
  theme(axis.text = element_text(angle = 45, hjust = 1))
ggpairs(paint_train, columns = c(5, 9:13),
        lower = list(continuous = wrap("points", alpha = 0.5, size = 0.3)))+
  theme(axis.text = element_text(angle = 45, hjust = 1))
ggpairs(paint_train, columns = c(5, 14:19),
        lower = list(continuous = wrap("points", alpha = 0.5, size = 0.3)))+
  theme(axis.text = element_text(angle = 45, hjust = 1))
ggpairs(paint_train, columns = c(5, 20:25),
        lower = list(continuous = wrap("points", alpha = 0.5, size = 0.3)))+
  theme(axis.text = element_text(angle = 45, hjust = 1))
ggpairs(paint_train, columns = c(5, 26:32),
        lower = list(continuous = wrap("points", alpha = 0.5, size = 0.3)))+
  theme(axis.text = element_text(angle = 45, hjust = 1))
```
  
  
For EDA in Part-II, we added pairwise plot to have a general view of the interactions of all the variables. Here we listed some interesting findings. 
 
 - The continuous variable *year* and *Surface* seem to be positively correlated with *logprice*. Additionally, there seems to be a non-linear relationship between *year* and *logprice*. However, after including $year^2$ and $year^3$, Neither diagnostic plots nor predictive coverage improved, so **we dropped the quadradic and cubic term**. 
 - The pairwise plot of *year* and other categorical variables revealed that there might be interaction effect between these variables, which we should consider in model building. 
 - The interactions between categorical variables is not that significant due to **class imbalance**. There are simply not enough observation for most of the categorical variable interaction. 
 - Based on the plot, we could conclude that the most important predictors are: *year*, *dealer*, *origin_cat*, *diff_origin*, *expensive*, *authorstyle*,*endbuyer*, *Interm*, *Surface*, *materialCat*, *nfigures*, *engraved*, *prevcoll*, *paired*, *finished*, *lrgfont*, *lands_sc*, *lands_elem*, *othgenre*, *discauth*. 
 


## Discussion of Preliminary Model
  

After the test data was updated at 11 P.M. on December 12th, we went back to our preliminary model to check our true results. It turns out that this linear regression model was actually achieving 95.6% coverage instead of the mentioned 65% coverage in our Part I write-up. The bias was also significantly lower than we thought, coming in at 120.3. Our RMSE was still large, though, resulting in a score of 2360.

```{r Preliminary Model, echo = F, message = F, warning = F}
prelim_data <- data.frame(Bias = 120.29, Coverage = 95.6, MaxDeviation = 52516.79, MeanAbsDeviation = 551.74, RMSE = 2363.27)

kable(prelim_data, 
      "latex", booktabs = T, 
      caption = "Results from Preliminary Model") %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  footnote(general = "Summarized from Werker")
```

This model has low bias and high variance, meaning that we overfit the data. Coverage is sufficient so we want to focus our attention on improving the RMSE. This can be achieved through the **bias-variance trade-off**. We can significantly reduce the variance if we induce a little more bias into our model, thus improving our RMSE score. 

The mean deviation was 551.74 but the max deviation was over 50,000. Our model is doing a good job on most predictions, but there are a few predictions that are extremely off, inflating the RMSE score. Our goal moving forward is to improve on these extreme cases and to introduce a little more bias into the model to produce a lower RMSE.

## Development of the final model

We tried several complex models to better depict the behaviour of the response variable. The findings of those models are summarised as below. 


### Random Forest

Since we have many variables and the interactions among them can be involved, a tree model seems to be appropriate for the setting. To alleviate the unstability of single tree models, we used random forest method to achieve more robust estimation. We select *year*, *dealer*, *origin_cat*, *diff_origin*, *expensive*, *authorstyle*,*endbuyer*, *Interm*, *Surface*, *materialCat*, *nfigures*, *engraved*, *prevcoll*, *paired*, *finished*, *lrgfont*, *lands_sc*, *lands_elem*, *othgenre*, *discauth* as predictors based on the EDA above. The 10 most important variables are *experience*, *year*, *Surface*, *endbuyer*, *dealer*, *materialCat*, *origin_cat*, *paired*, *Irgfont* and *finished*. Below is the important variable plot and the 5 least important variable table. We will discarded these 5 least important variables in further modeling. 
  
```{r tree}
set.seed(222)
rf <- randomForest(logprice ~ year + dealer + origin_cat + diff_origin + expensive + 
                         authorstyle + endbuyer + Interm + Surface + materialCat + 
                         nfigures + engraved + prevcoll + paired + finished + lrgfont + 
                         lands_sc + lands_elem + othgenre + discauth, 
                   data = paint_train, mytry = 6, importance = T)

varImpPlot(rf)
ImpMeasure<-data.frame(Overall = varImp(rf)$Overall)
ImpMeasure$Vars<-rownames(varImp(rf))
```

```{r rf table}
kable(ImpMeasure[order(-ImpMeasure$Overall),][15:19,], 
      "latex", booktabs = T, 
      digits = 3, caption = "Least 5 important variables of RF") %>% 
  kable_styling(position = "center", latex_options = c("striped", "hold_position"))

# training set 
rf_pred_train <- predict(rf, newdata = paint_train, type = "response")
rmse = function(y, ypred) {
  rmse = sqrt(mean((y - ypred)^2))
return(rmse)
}

rf_rmse <- rmse(exp(paint_train$logprice), exp(rf_pred_train))
# compare <- cbind(paint_train, ypred = rf_pred_train)
# ggplot(compare, aes(x = logprice, y = ypred)) +
#   geom_point(size = 0.5) + 
#   geom_abline(intercept = 0, slope = 1, col = "light pink") +
#   geom_smooth(method = "lm", se = T)
```
  
To assess the performance of the random forest model, we first evaluated it using training set which achieved a training RMSE of `r rf_rmse`. However when we used it for test set, the prediction contains only a point estimate instead of a prediction interval. We tried to compute the interval using the quantile method, but the coverage is not ideal, which might due to narrower interval. So we move on to other variable selection method like Bayesian Model Averaging. 

### still need predictive checks ###


```{r test set validation}
# pred1 <- predict(rf, newdata = paint_test, predict.all=TRUE)
# 
# pred1_int <- apply(pred1$individual, 1, function(x) {
#   quantile(x, c(0.5, 0.025, 0.975))
# })
# 
# predictions_rf <- t(exp(pred1_int)) %>% as.data.frame()
# colnames(predictions_rf) <- c("fit", "lwr", "upr")
```

### Lasso
Apart from including random forests in our model development, we also put consideration into Lasso since this model is suitable for both variable selection and preventing overfitting through shrinkage. However, due to the fact that we have most of variables as categorical, some with multiple levels, it is hard to decide whether to normalize these predictors before modeling because if we do so, the result will depend on class prevalence and for multilevel predictors, we need to regroup them. The result will vary depending on our reference level and generate more difficulty for interpretation as well. In addition, similar to trees, Lasso doesn’t have an existing prediction interval and we will need to use bootstrap to obtain such interval. Thus, to make our model easier to understand and more convenient for predictions, we decide to move on and do not include Lasso in the model-building process.

### Bayesian Model Averaging

```{r full model}
# paint_train$year <- scale(paint_train$year, scale = F)
# model_ini <- lm(logprice ~ year + dealer + origin_cat + diff_origin +
#                          authorstyle + endbuyer + Interm + Surface + materialCat + 
#                          nfigures + engraved + prevcoll + paired + finished + lrgfont + 
#                          lands_sc + lands_elem + othgenre + discauth + (year + authorstyle + discauth):dealer + year:discauth, data = paint_train)
# 
# n <- nrow(paint_train)
# ini_bic <- step(model_ini, trace = F, k = log(n))
# ini_aic <- step(model_ini, trace = F, k = 2)
```
  
From the analysis so far our main problem is **overfitting**. This might be improved with Bayesian Model Averaging (BMA) which is an application of Bayesian inference to the problems of model selection, combined estimation and prediction that produces a straightforward model choice criteria and less risky predictions. [1]

In addition to the variables we used in the random forrest model, we also added interactions based on the p-value of these interactions (See Appendix for the summary of the full model), namely *dealer* with *year*, *authorstyle* and *discauth*, *year* and *discauth*. The results can be summarised as follows: 

```{r bma}
library(BAS)
model_ini <- lm(logprice ~ year + dealer + origin_cat + diff_origin + expensive + 
                         authorstyle + endbuyer + Interm + Surface + materialCat + 
                         nfigures + engraved + prevcoll + paired + finished + lrgfont + 
                         lands_sc + lands_elem + othgenre + discauth + (year + authorstyle + discauth):dealer + year:discauth, data = paint_train)

lm_bas <- bas.lm(as.formula(model_ini), data = paint_train, 
              prior = "g-prior", alpha = nrow(paint_train), 
              modelprior = uniform(), method = "MCMC")
plot(lm_bas, which = 4)

# estimates under BMA model
summary.bas <- confint(coef(lm_bas))
df4 <- data.frame(variable = lm_bas$namesx, 
                  coef = summary.bas[,3],
                  lwr = summary.bas[,1],
                  upr = summary.bas[,2],
                  row.names = NULL) %>% arrange(desc(coef))
```


```{r bma table}
kable(df4, "latex", booktabs = T,
      digits = 3, caption = "Coefficient Summary of Best BMA model") %>% 
  kable_styling(position = "center", latex_options = c("striped", "hold_position"))

#predictions
# x = predict(lm_bas, estimator = "BMA",newdata = paint_test, se.fit = T)
# interval = confint(x, parm = "pred")
# confint <- exp(interval)
# predictions <- data.frame(fit = confint[,3], lwr = confint[,1], upr = confint[,2])
```

From the marginal inclusion probability plot, we should exclude *materialCat*, *nfigures*, *lands_elem*, *auhtorstyle*:*dealer* since their margnial inclusion probability is less than 0.5. 


After cross referencing the result of random forrest and BMA, we decided to give another shot with simple models. So we discarded the variables that are not significant and refit a linear model. The problem of overfitting still exists. To further select variables, we used Added variable plots, which shows us the relationship between the response variable and one of the predictors in the regression model, after controlling for the presence of other predictors. 

```{r new linear model}
new_lm <- lm(logprice ~ year + dealer + origin_cat + diff_origin +
                         authorstyle + endbuyer + Interm + Surface +  
                         paired + finished + lrgfont + 
                         year:dealer, data = paint_train)
avPlots(new_lm)
```

From the Added variable plots above, we observed that the regression line is nearly flat with variables *paired*, *origin_cat* and *year*:*dealer*, so we deleted these variables to refit the linear model. **Our final model can be summarised as follows**: 

$$
\begin{aligned}
\text{logprice} &= \beta_0 + \beta_1 \text{year} + \beta_2 \text{dealer} + \beta_3 \text{expensive} + \beta_4 \text{authorstyle} + \beta_5 \text{endbuyer} \\
&+ \beta_6 \text{Interm} + \beta_7 \text{Surface} + \beta_8 \text{finished} + \beta_9 \text{Irgfont} + \beta_{10} \text{diff-origin} + \epsilon
\end{aligned}
$$

```{r final model, fig.asp=1}
new <- lm(logprice ~ year + dealer + expensive + authorstyle + endbuyer + Interm + Surface + finished + lrgfont + diff_origin, data = paint_train)
final_model <- new
```



```{r predict-model2, echo=FALSE}
# replace model1 with model2 here
# paint_test$year <- scale(paint_test$year, scale = F)
predictions = as.data.frame(
  exp(predict(final_model, newdata=paint_test, 
              interval = "pred")))
save(predictions, file="predict-test.Rdata")
```
  
## Assessment of the final model
```{r res plot, fig.asp=1}
par(mfrow = c(2, 2))
plot(final_model)
```
Looking at the diagnostic plots, our final model seems to satisfy the assumptions of linear regression resonablly well. From the Residual vs Fitted plot we can see equally spread residuals around a horizontal line without any distinct patterns; The Normal Q-Q plot shows the residuals are almost normally-distributed. The Scale-Location plot shows that homoscedasticity is met. The Residual vs Leverage plot does not show any points that are influential or falls outside of Cook's distance line. 
  
```{r vif}
vif <- vif(final_model) %>% as.data.frame()
kable(vif, "latex", booktabs = T,
      digits = 3,caption = "VIF of final model") %>% 
  kable_styling(position = "center", latex_options = c("striped", "HOLD_position"))
```
  
To check for the multicollinearity problem, we used variance inflation factor (VIF). The result is in the table above. Issue of multicollinearity is negligible for no VIF exceeds 5.  


### Predictions of Validation set and Top 10 paintings
```{r validation}
#make same changes to validation set
load("paintings_validation.RData")
# Fix position > 1
paintings_validation$position[paintings_validation$position > 1] <- paintings_validation$position[paintings_validation$position > 1]/100

# regroup some categorical variables
paintings_validation <- paintings_validation %>%
  mutate(winningbiddertype = as.factor(dplyr::recode(na_if(winningbiddertype,""),
                                              .missing = 'U')),
         dealer = as.factor(dplyr::recode(dealer, 
                                          'L' = 'LP', 
                                          'P' = 'LP')), 
         endbuyer = as.factor(dplyr::recode(na_if(endbuyer,""),
                                     .missing = 'EU',
                                     'E' = 'EU', 
                                     'U' = 'EU',
                                     'B' = 'C')),
         Interm = as.factor(dplyr::recode(Interm,
                                   .missing = 0,
                                   `0` = 0,
                                   `1` = 1)),
         authorstyle = dplyr::recode(authorstyle,
                                      "n/a" = 0,
                                      .default = 1),
         type_intermed = as.factor(dplyr::recode(na_if(type_intermed,''),
                                          .missing='Unknown')),
         Shape = as.factor(dplyr::recode(na_if(Shape,""),
                                  .missing = 'other',
                                  'squ_rect' = 'squ_rect',
                                  .default = 'other')),
         materialCat = as.factor(dplyr::recode(na_if(materialCat,""),
                                        .missing = 'other')),
         school_pntg = as.factor(dplyr::recode(school_pntg,
                                               'S' = 'X',
                                               'A' = 'X',
                                               'G' = 'X')), 

         origin_cat = as.factor(dplyr::recode(origin_cat,
                                    "S" = "O")), 

         nfigures = as.factor(dplyr::recode(nfigures,
                                            `0` = 0,
                                            .default = 1))) %>%
  # change variables into appropriate format

  mutate_at(vars(dealer, origin_author, origin_cat, school_pntg, 
                 diff_origin, artistliving, authorstyle, 
                 winningbiddertype, endbuyer, Interm, type_intermed, 
                 material, mat, materialCat, Shape, engraved, original, 
                 prevcoll, othartist, paired, figures, finished, lrgfont, 
                 relig, landsALL, lands_sc, lands_elem, lands_figs, lands_ment, 
                 arch, mytho, peasant, othgenre, singlefig, portrait, 
                 still_life, discauth, history, allegory, pastorale,other), as.factor) 

# impute Surface on different groups

paintings_validation <- paintings_validation %>% mutate(Key = seq(1:nrow(paintings_validation)))

paint1 <- paintings_validation %>% filter(materialCat == 'canvas', relig == 1) %>% 
  mutate(Surface = dplyr::recode(Surface,
                          `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm = T)))

paint2 <- paintings_validation %>% filter(materialCat == 'canvas', relig == 0) %>%
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm=T)))

paint3 <- paintings_validation %>% filter(materialCat == 'copper', relig == 1) %>% 
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm = T)))

paint4 <- paintings_validation %>% filter(materialCat == 'copper', relig == 0) %>%
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm=T)))

paint5 <- paintings_validation %>% filter(materialCat == 'other', relig == 1) %>% 

  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm = T)))

paint6 <- paintings_validation %>% filter(materialCat == 'other', relig == 0) %>%
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm=T)))

paint7 <- paintings_validation %>% filter(materialCat == 'wood', relig == 1) %>% 
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm = T)))

paint8 <- paintings_validation %>% filter(materialCat == 'wood', relig == 0) %>%
  mutate(Surface = dplyr::recode(Surface,
                                 `0` = median(Surface, na.rm = T),
                          .missing = median(Surface, na.rm=T)))

paintings_validation <- rbind(paint1, paint2, paint3, paint4, paint5, paint6, paint7, paint8) %>% 
  arrange(Key) %>% 
  select(-Key) %>% 
  dplyr::select(-c("sale", "lot", "count","subject", "author", "origin_author",
                   "winningbidder","type_intermed","material","mat", "still_life", "portrait",
                   "Diam_in","Surface_Rnd","Surface_Rect","Width_in","Height_in","other",
                   "pastorale","history","lands_ment","original","allegory","position",
                   "school_pntg", "winningbiddertype", "figures", "singlefig"))

paintings_validation$Surface <- log(paintings_validation$Surface)

remove <- c("attributed to ", "after ", "in the manner of ", "in the taste of ", "in the genre of ", "in the style of ")

paintings_validation$authorstandard <- str_remove_all(paintings_validation$authorstandard, 
                                             paste(remove, collapse = "|"))

level <- c(1, 0)

train_author <- paint_train %>% 
  group_by(authorstandard) %>% 
  summarise(avg_price = mean(price)) %>% 
  arrange(desc(avg_price)) %>% 
  mutate(expensive = case_when(avg_price >= 2000 ~ level[1],
                           avg_price < 2000 ~ level[2]))

# attribute each author name to its group
author_group = map(level, ~train_author$authorstandard[train_author$expensive == .x]) %>%
  set_names(level)

paintings_validation <- paintings_validation %>% 
  mutate(expensive = case_when(authorstandard %in% author_group[[1]] ~ level[1],
                              authorstandard %in% author_group[[2]] ~ level[2]) %>% as.factor)
paintings_validation$expensive[is.na(paintings_validation$expensive)] <- level[2]

```


```{r top paintings}
#predict top 10
fitted <- exp(predict(final_model, newdata = paintings_validation))
Top10 <- cbind(paintings_validation, fitted) %>% arrange(desc(fitted)) %>% slice(1:10) %>% select(fitted,year,dealer,expensive,authorstyle,endbuyer,Interm ,Surface,finished,lrgfont,diff_origin)
kable(Top10, "latex", booktabs = T, digits = 3,
      caption="Top 10 paintings")%>%
  kable_styling(position = "center", latex_options = c("striped", "HOLD_position"))
```
Using our model for predicting price for validation data set, we got our top 10 valuable paintings.From this we can learn what are some desirable features of the paintings based on our model through observing these valuable paintings all share certain common features, such as they are all from the same dealer, R. In addition, endbuyers are mostly from category C, the dealer devotes an additional paragraph and an intermediary is involved in the transaction etc. This is quite expected due to the way we constructed our model. 

```{r pred}
predictions_validation = as.data.frame(
  exp(predict(final_model, newdata=paintings_validation, 
              interval = "pred")))
save(predictions_validation, file="prediction-validation.Rdata")
```

## Conclusion

```{r coef summary}
tb_final <- broom::tidy(final_model, conf.level=0.95,
                   conf.int = TRUE, exponentiate=T)
kable(tb_final, "latex", booktabs = T, digits = 3,
      caption="Coefficient Summary for Final Model") %>%
  kable_styling(position = "center", latex_options = c("striped", "HOLD_position")) %>% 
  footnote(general = "The coefficients have been exponentiated.")
```

Looking at the coefficient summary table, we can get the following conclusion. 

First of all, in our model we got the most important variables *year*, *dealer*, *expensive*, *authorstyle*, *endbuyer* ,*Interm*, *Surface*, *finished*, *lrgfont*, *diff_origin*. 

Then, holding all other variables constant,

  - On average, one unit increase in *year* will lead to 12.0% increase in price. We are 95% confident the increase is between about 10.5% and 13.6%.  
 
  - In data manipulation part, we regrouped *dealer* by grouping 'L' and 'P' together as 'LP' since their corresponding average logprices are similar. Compared to dealer J, dealer LP is expected to lead to 156.8% increase in price, and we are 95% confident the decrease is between about 106.0% and 220.0%; Dealer R is expected to lead to 435.6% increase in price, and we are 95% confident the increase is between about 337.4% and 555.8%.
  
  - If the painting is drawn by an artist whose paintings' average price is higher than $2000, the price is expected to increase by 260.5%. We are 95% confident the increase is between about 192.6% and 344.2%.
  
  - If the authors name is introduced, the price is expected to decrease by 61.2%. We are 95% confident the decrease is between about 48.2% and 70.9%.
  
  - In data manipulation part, we regrouped *endbuyer* by grouping 'U' (identity unknown), 'E'  (expert organizing the sale) and blank data (no information) together as 'EU', grouping 'B' (buyer) and 'C' (collector) together as 'C' and left 'D' (dealer) as it was. Compared to an endbuyer in group 'C', a group 'D' endbuyer is expected to lead to 21.2% decrease in price, and we are 95% confident the decrease is between about 4.1% and 35.4%; A group 'EU' endbuyer is expected to lead to 50.6% decrease in price, and we are 95% confident the decrease is between about 39.6% and 59.6%.  

  - If an intermediary is involved in the transaction, the price is expected to increase by 99.6%. We are 95% confident the increase is between about 53.7% and 159.1%.

  - We expect 10% increase in *Surface* will increase the price by 3.0% ($1.1^{\hat{\beta}_1} - 1$). We are 95% confident the increase is between about 2.5% and 3.5%.

  - If the the painting is finished, the price is expected to increase by 135.1%. We are 95% confident the increase is between about 96.9% and 180.6%.
  
  - If the dealer devotes an additional paragraph, the price is expected to increase by 143.6%. We are 95% confident the increase is between about 92.6% and 208.0%.
  
  - If origin_author is different than origin_cat, the price is expected to decrease by 38.7%. We are 95% confident the increase is between about 27.6% and 48.1%.

Looking at the p-values, we find that all variables are extremelly important.

In EDA process of part-I, we imputed the NA's in *Surface* to median value of *Surface*, we discarded the variable *authorstandard* and we grouped *dealer* and *endbuyer* into 4 and 5 levels respectively. And then we fitted a linear model. However, in part-II, our model were not good as we expected. We returned to EDA process and realized that there was still some infomation in raw data we did not pay enough attention. And thus we reworked the data manipulation process. In part-II, we devided the surface data into 8 groups based on the correlated data and imputed median value for each group respectively. We created a binary variable *expensive* representing if the painting is drawn by a painter whose paintings' averaging price is higher than $2000. And we also regrouped dealer and endbuyer to less levels to avoid overfitting. After data re-manipulation, the model performed better. 

Before the test data was updated, we always felt upset because the coverage was always lower than our expectaiton even if we thought our model was already good enough. Some of our team members were so disappointed that they even thought about discarding *year* since this operation improved the coverage a lot. But luckily we were pretty sure that all operations need to be reasonable. We could not randomly discard some variables just for better coverage and RMSE. So we still followed the rigorous modeling process to fit our model, even if we did not get a score in wercker.

After a few attempts, we had to give up our most prefered model Random Forests since it could not yield prediction interval and the quantile method was not ideal. We then used Bayesian Model Averaging to do feature selection and cross referenced the results of RF and BMA and fitted a new linear model, which achieved relatively great performance. We found that succinct model usually have higher coverage and easy interpretability so it's easier for clients to understand and linear model is generally a great model choice. 

In terms of painting price prediction, we think that due to the particularity of art, the author often has a great impact on the price. Besides, year of sale, dealer, if the authors name is introduced, type of end buyer, whether or not an intermediary is involved in the transaction, surface of painting, if the painting is finished, if the dealer devotes an additional paragraph, if origin of author is different than origin of painting also have a great impact on the price of paintings.

## Reference
  
[1] Hoeting, Jennifer A., et al. “Bayesian Model Averaging: A Tutorial.” Statistical Science, vol. 14, no. 4, 1999, pp. 382–401. JSTOR, www.jstor.org/stable/2676803.
  
## Appendix
```{r full}
full_model <- lm(logprice ~ (year + dealer + origin_cat + diff_origin +
                         authorstyle + endbuyer + Interm + Surface + materialCat + 
                         nfigures + engraved + prevcoll + paired + finished + lrgfont + 
                         lands_sc + lands_elem + othgenre + discauth)^2, data = paint_train)
tb_full <- broom::tidy(full_model, conf.level=0.95,
                   conf.int = TRUE, exponentiate=T)
kable(tb_full, "latex", booktabs = T, digits = 3,
      caption="Coefficient Summary for Full Model") %>%
  kable_styling(position = "center", latex_options = c("striped", "HOLD_position")) %>% 
  footnote(general = "The coefficients have been exponentiated.")
```




